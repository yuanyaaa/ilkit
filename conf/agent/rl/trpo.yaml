algo: trpo
gamma: 0.99
batch_size: 256
rollout_steps: 2048
lambda_: 0.97
norm_adv: true
use_td_lambda: true
buffer_size: 50_000

# conjugate gradient param
residual_tol: !!float 1e-10
cg_steps: 10
damping: !!float 1e-1

# line search param
beta: 0.8
max_backtrack: 15
accept_ratio: !!float 1e-1
delta: !!float 1e-2

actor:
  net_arch: [256, 256]
  activation_fn: ReLU
  state_std_independent: False

value_net:
  net_arch: [256, 256]
  activation_fn: ReLU
  optimizer: Adam
  lr: !!float 1e-3
  n_update: 5